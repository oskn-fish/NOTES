# 学んだこと
- 言語モデルは文章（単語系列）の発生確率を近似するモデル．
- 特に，自己回帰言語モデルでは，文章の各単語は，その単語以前の系列に対して条件付して生成されているという仮定のもとでモデルを構築している．
- SOTAの言語モデルにおいてはAttentionという機構を用いたTransformerという構造を用いているものがある．
- GPTはナンバリングが上がっても基本的な構造は変わっておらず，性能向上は学習データやモデルサイズの向上によるところが大きい（？）
- 言語モデルの性能は計算資源・データセットサイズ・パラメータ数に関してべき乗則に従う．
- モデルサイズが一定の大きさになって初めて特定の問題が解けるようになる現象があり，Emerget Abilityという．
- 入力に，出入力の例を提示することをFew shot learningとかIn context learningなどと呼ぶ．
- 近年のモデルはFine tuningさえ行わずにPromptingでもタスクをこなすことができる．
- 言語モデルと強化学習を組み合わせた研究もある．（ゲーム内エージェント・ロボット制御）
- 外部ツールを用いることのできるモデル（Augmented Language Models）もある．
- モデルの出力が，暗黙的に期待する性質を持つことをAlignmentという．
- Alignmentを実現するために人手でフィードバックを行うことをRLHF(Reinforcement Learning with Human Feedback)という．
- ただし，人力で行っているため，出力にバイアスがかかる．
- 学習データに関する著作権の問題が難しそう．